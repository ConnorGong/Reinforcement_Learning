**第三讲 方格世界 DP**  
*初始情况*  
1.只有移动到指定位置,Reward=1.否则Reward=-1  
2.States-space(4*4  终止的方格+非终止)  
3.Action-space(n,e,s,w)  
4.转移概率(1/4  感觉这就是相当于指定Action的策略)  
5. 折扣因子γ=1  

*目的*  
给定某一策略(比如转移概率)，计算每一个方格最终的状态价值  

*公式*  
1.γ=1  
2.Q(S) = Sum( P * (Reward + γ*Q'(S',a)) P是采用动作a的概率(本题有东南西北四个可能动作)  
*异步更新*  
特别注意下Q(S',a)是不是真正意义上的尚未发生的价值--关键点2  
3.更新Q

*idea*  
通过收敛的状态价值表 得到最优策略  

**关键点**  
1.如果无法获取一个状态的所有可能后续(one-step)状态，那么就不能使用动态规划算法来求解  
*2.异步更新价值的方法，即某一时刻状态的价值由前一时刻状态价值来计算*  
